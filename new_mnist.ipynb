{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem description:##\n",
    "\n",
    "Our goal is to transform the multi-class classification problem (using famous MNIST dataset) into a binary. For this purpose, we combine 2 original MNIST images (digits, size =28x28) into one, after that each images contains 2 digits (new size = 56x28). So now we want to teach the neural network to find images that contain the number 4 (class=1, other images: class=0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import Image\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# the following line is not required if Dataset is installed as a python package.\n",
    "sys.path.append(\"../..\")\n",
    "from dataset import Pipeline, B, C, F, V\n",
    "import mnist\n",
    "from dataset.models.tf import ResNet18\n",
    "from dataset import DatasetIndex, Dataset, Batch\n",
    "\n",
    "from dataset import B, V, F, R, P, action, ImagesBatch\n",
    "from dataset.models.tf import TFModel\n",
    "from dataset.models.tf.layers import conv_block\n",
    "from dataset.batch_image import transform_actions\n",
    "\n",
    "from dataset.opensets import MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Define Batch class which holds data and contains processing functions ####\n",
    "**(in our case we can choose any default class like ImagesBatch)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "@transform_actions(prefix='_', suffix='_', wrapper='apply_transform')\n",
    "class MnistBatch(ImagesBatch):\n",
    "    components = 'images', 'labels'\n",
    "\n",
    "    def _shift_flattened_(self, image, max_margin=8):\n",
    "        padded = np.pad(self._to_array_(image),\n",
    "                        pad_width=[[max_margin, max_margin], [max_margin, max_margin], [0, 0]],\n",
    "                        mode='minimum')\n",
    "        left_lower = np.random.randint(2 * max_margin, size=2)\n",
    "        slicing = (slice(left_lower[0], left_lower[0] + 28),\n",
    "                   slice(left_lower[1], left_lower[1] + 28))\n",
    "        return self._to_pil_(padded[slicing])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's load data and create the dataset using MNIST openset: ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Extracting /var/folders/ns/3lqd0mjj7vg1pt0gj5ph0nw80000gn/T/train-labels-idx1-ubyte.gz\n",
      "Extracting /var/folders/ns/3lqd0mjj7vg1pt0gj5ph0nw80000gn/T/t10k-labels-idx1-ubyte.gz\n",
      "Extracting /var/folders/ns/3lqd0mjj7vg1pt0gj5ph0nw80000gn/T/train-images-idx3-ubyte.gz\n",
      "Extracting /var/folders/ns/3lqd0mjj7vg1pt0gj5ph0nw80000gn/T/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 1/18 [32:56<9:20:07, 1976.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 1/18 [23:59<6:47:43, 1439.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 1/18 [10:52<3:04:50, 652.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "dataset=MNIST(batch_class=MnistBatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***Images and their labels are in preloaded.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odt = original data\n",
    "odt=dataset.train.preloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***So \"odt[0]\" corresponds to a set of images and \"odt[1]\" corresponds to the list of labels***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample pictures from the MNIST dataset: ####\n",
    "![MNIST dataset](https://m-alcu.github.io/assets/mnist.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create two lists - \"four\" and \"others\". #### \n",
    "**List \"four\" contains the indices of images of figure 4, list \"others\" - all the remaining indices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "four=[]\n",
    "others=[]\n",
    "for i in range(0, len(odt[1])):\n",
    "    if odt[1][i]==4:\n",
    "        four.append(i)\n",
    "    else:\n",
    "        others.append(i)\n",
    "random.shuffle(others)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new images array (train_4), which contain images with number 4#####\n",
    "**Also create labels array y_4 (all elements have class=1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_image_size 56 x 28\n",
    "train_4 = odt[0][four[0]]\n",
    "train_4 = np.append(train_4, odt[0][others[0]],axis=0)\n",
    "zipped = zip(four, others[0:len(four)])\n",
    "for i,j in zipped:\n",
    "    if i != four[0]:\n",
    "        train_4 = np.append(train_4, odt[0][i], axis=0)\n",
    "        train_4 = np.append(train_4, odt[0][j], axis=0)\n",
    "train_4 = train_4.reshape((len(four),56,28))\n",
    "y_4 = np.ones((len(four)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new images array (train_others), which contain images with other numbers#####\n",
    "**Also create labels array y_others (all elements have class=0)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_others = odt[0][others[len(four)]]\n",
    "for i in others[len(four):len(four)*3]:\n",
    "    if i != others[len(four)]:\n",
    "        train_others = np.append(train_others, odt[0][i], axis=0)\n",
    "train_others = train_others.reshape((len(four),56,28))\n",
    "y_others = np.zeros((len(four)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's combine the received arrays into one array ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_new = np.concatenate((train_4, train_others), axis=0)\n",
    "train_labels_new = np.concatenate((y_4, y_others),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample pictures after transformations ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=800x200 at 0x13A5B5978>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_1 = Image.new('L', (800,200))\n",
    "\n",
    "for i in range(0,4):\n",
    "    class_1.paste(Image.fromarray(train_4[i]).resize([200,200]), (0+200*i,0))\n",
    "class_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=800x200 at 0x133307A90>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_0 = Image.new('L', (800,200))\n",
    "\n",
    "for i in range(0,4):\n",
    "    class_0.paste(Image.fromarray(train_others[i]).resize([200,200]), (0+200*i,0))\n",
    "class_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we prepare to create a new dataset ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_MNIST_data = train_images_new, train_labels_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_MNIST_index = list(range(train_labels_new.shape[0]))\n",
    "new_MNIST_dataset = Dataset(new_MNIST_index, batch_class=MnistBatch, preloaded=new_MNIST_data)\n",
    "new_MNIST_dataset.cv_split([.8, .1, .1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For example, let's use config for ResNet18 model from dataset.models.tf ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(model=ResNet18) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When config is defined, next step is to create a pipeline. ####\n",
    "\n",
    "\n",
    "*Also we add to default pipeline rotation transform. Now each image rotate with probability 0.5 by angle = 180 degree.*\n",
    "\n",
    "*As a result, the position of figure 4 will not be the same [before this (as you can see in sample pictures) all figures 4 were at the top]*\n",
    "\n",
    "*Due to this trasformation we have complicated the learning process, adding variance in data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_template = (Pipeline(config=config)\n",
    "                .init_variable('loss_history', init_on_each_run=list)\n",
    "                .init_variable('current_loss', init_on_each_run=0)\n",
    "                .shift_flattened()\n",
    "                .init_model('dynamic', C('model'), 'conv_nn',\n",
    "                            config={'inputs': dict(images={'shape': B('image_shape')},\n",
    "                                                   labels={'classes': 2, 'transform': 'ohe', 'name': 'targets'}),\n",
    "                                    'input_block/inputs': 'images',\n",
    "                                    'output': dict(ops=['accuracy'])})\n",
    "                .rotate(angle=180, p=0.5)  \n",
    "                .to_array()\n",
    "                .train_model('conv_nn', fetches='loss',\n",
    "                                     feed_dict={'images': B('images'),\n",
    "                                                'labels': B('labels')},\n",
    "                             save_to=V('current_loss'))\n",
    "                .update_variable('loss_history', V('current_loss'), mode='a')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model ####\n",
    "**Apply a dataset to a template pipeline to create a runnable pipeline:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline = (train_template << new_MNIST_dataset.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Run the pipeline:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█▍        | 2/14 [00:31<03:11, 15.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|██▏       | 3/14 [00:57<03:28, 18.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|██▊       | 4/14 [01:22<03:26, 20.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 5/14 [01:47<03:16, 21.87s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████▎     | 6/14 [02:14<03:07, 23.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 7/14 [02:44<02:58, 25.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████▋    | 8/14 [03:15<02:43, 27.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|██████▍   | 9/14 [03:45<02:19, 27.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████▏  | 10/14 [04:16<01:55, 28.81s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|███████▊  | 11/14 [04:41<01:23, 27.87s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████▌ | 12/14 [05:09<00:55, 27.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|█████████▎| 13/14 [05:37<00:27, 27.81s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 14/14 [06:02<00:00, 27.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<dataset.pipeline.Pipeline at 0x1335dd898>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 640\n",
    "train_pipeline.run(BATCH_SIZE, shuffle=True, n_epochs=1, drop_last=True, bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the model ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [05:28<00:00, 328.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 1/18 [19:17<5:27:58, 1157.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (640, 56, 28, 1) for Tensor 'ResNet18/inputs/images:0', which has shape '(?, 28, 28, 1)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-183-d4ba0c9ed08a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                                \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'labels'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                save_to=V('accuracy'), mode='a')\n\u001b[0;32m----> 8\u001b[0;31m                 \u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/dataset/pipeline.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'n_epochs'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_epochs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pipeline will never stop as n_epochs=None'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/dataset/pipeline.py\u001b[0m in \u001b[0;36mgen_batch\u001b[0;34m(self, batch_size, shuffle, n_epochs, drop_last, prefetch, on_iter, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1052\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                     \u001b[0mbatch_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mSkipBatchException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/dataset/pipeline.py\u001b[0m in \u001b[0;36mexecute_for\u001b[0;34m(self, batch, new_loop)\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m         \u001b[0mbatch_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exec_all_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0mbatch_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_res\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/dataset/pipeline.py\u001b[0m in \u001b[0;36m_exec_all_actions\u001b[0;34m(self, batch, action_list)\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0m_action\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_ACTIONS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m                 \u001b[0maction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ACTIONS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_action\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m                 \u001b[0maction_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mjoin_batches\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/dataset/pipeline.py\u001b[0m in \u001b[0;36m_exec_predict_model\u001b[0;34m(self, batch, action)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_model_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'save_to'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mode'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/dataset/models/tf/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0m_feed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fill_feed_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fill_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'predictions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_feed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fill_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1114\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1116\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1117\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (640, 56, 28, 1) for Tensor 'ResNet18/inputs/images:0', which has shape '(?, 28, 28, 1)'"
     ]
    }
   ],
   "source": [
    "test_pipeline = (new_MNIST_dataset.test.p\n",
    "                .import_model('conv_nn', train_pipeline)\n",
    "                .init_variable('accuracy', init_on_each_run=list)\n",
    "                .to_array()\n",
    "                .predict_model('conv_nn', fetches='output_accuracy', \n",
    "                               feed_dict={'images': B('images'), 'labels': B('labels')},\n",
    "                               save_to=V('accuracy'), mode='a')\n",
    "                .run(BATCH_SIZE, shuffle=True, n_epochs=1, drop_last=True, bar=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy   0.99\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.array(test_pipeline.get_variable('accuracy')).mean()\n",
    "print('Accuracy {:6.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
